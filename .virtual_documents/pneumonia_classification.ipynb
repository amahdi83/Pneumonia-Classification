





import os
import time
import cv2
import random
import numpy as np
from scipy.ndimage import zoom, shift, rotate
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input, GlobalAveragePooling2D, BatchNormalization, MaxPool2D
from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import seaborn as sns
from livelossplot import PlotLossesKeras
import warnings
warnings.filterwarnings('ignore')
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# Define custom progress bar format with ANSI color codes
bar_format = "\033[0;30mLoading Images: \033[0;32m{bar:20}\033[0m {n_fmt}/{total_fmt} {percentage:3.0f}%"


# Parameters
img_size = 224
batch_size = 32
epochs = 50
lr = 5e-5
loss = 'binary_crossentropy'


# Define data path
train_n_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "train", "NORMAL")
train_p_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "train", "PNEUMONIA")
val_n_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "val", "NORMAL")
val_p_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "val", "PNEUMONIA")
test_n_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "test", "NORMAL")
test_p_path = os.path.join(os.getcwd(), "datasets", "chest_xray", "test", "PNEUMONIA")


# Get the file names
train_n_names = os.listdir(train_n_path)
train_p_names = os.listdir(train_p_path)
val_n_names = os.listdir(val_n_path)
val_p_names = os.listdir(val_p_path)
test_n_names = os.listdir(test_n_path)
test_p_names = os.listdir(test_p_path)


# Data for plotting
categories = ['Normal', 'Pneumonia']
train_counts = [len(train_n_names), len(train_p_names)]
val_counts = [len(val_n_names), len(val_p_names)]
test_counts = [len(test_n_names), len(test_p_names)]


# Create subplots
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

# Function to add text on top of bars
def add_labels(ax, counts):
    # Get the y-axis limit
    y_lim = ax.get_ylim()[1]
    for i, count in enumerate(counts):
        # Add a label above the bar but below the maximum y-axis limit
        label_y = min(count + 10, y_lim - 10)  # Ensure label stays within plot
        ax.text(i, label_y, str(count), ha='center', va='bottom')

# Train dataset bar plot
axs[0].bar(categories, train_counts, color=['#1f77b4', '#ff7f0e'])
axs[0].set_title('Train Dataset')
axs[0].set_ylabel('Number of Images')
axs[0].set_ylim(0, max(train_counts) + 500)  # Adjust y-axis limit
add_labels(axs[0], train_counts)  # Add labels

# Validation dataset bar plot
axs[1].bar(categories, val_counts, color=['#1f77b4', '#ff7f0e'])
axs[1].set_title('Validation Dataset')
axs[1].set_ylim(0, max(val_counts) + 10)  # Adjust y-axis limit
add_labels(axs[1], val_counts)  # Add labels

# Test dataset bar plot
axs[2].bar(categories, test_counts, color=['#1f77b4', '#ff7f0e'])
axs[2].set_title('Test Dataset')
axs[2].set_ylim(0, max(test_counts) + 100)  # Adjust y-axis limit
add_labels(axs[2], test_counts)  # Add labels

# Adjust layout and show plot
plt.tight_layout()
plt.show()


# Create subplots
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

# Training Pie Chart
axs[0].pie(train_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[0].set_title('Train Dataset')

# Validation Pie Chart
axs[1].pie(val_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[1].set_title('Validation Dataset')

# Test Pie Chart
axs[2].pie(test_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[2].set_title('Test Dataset')

# Adjust layout
plt.tight_layout()

# Show plot
plt.show()


total_counts = [train_counts[0]+val_counts[0]+test_counts[0], train_counts[1]+val_counts[1]+test_counts[1]]

# Create subplots
fig, axs = plt.subplots(1, 2, figsize=(15, 5))

# Total dataset bar plot
axs[0].bar(categories, total_counts, color=['#1f77b4', '#ff7f0e'])
axs[0].set_ylabel('Number of Images')
axs[0].set_ylim(0, max(train_counts) + 1000)  # Adjust y-axis limit
add_labels(axs[0], total_counts)  # Add labels

# Total dataset Pie Chart
axs[1].pie(total_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])

# Adjust layout
plt.tight_layout()

# Show plot
plt.show()





def read_images(path, names):
    img_data = np.zeros((len(names), img_size, img_size, 3), dtype=np.float32)

    # Define custom progress bar format with ANSI color codes
    #bar_format = "\033[0;30mLoading Images: \033[0;32m{bar:20}\033[0m {n_fmt}/{total_fmt} {percentage:3.0f}%"
    
    for i, name in tqdm(enumerate(names), total=len(names), desc="Loading Images", bar_format=bar_format):
    #for i in range(len(names)):
        img = cv2.imread(os.path.join(path, name))[..., ::-1]
        img_data[i, ...] = cv2.resize(img, (img_size, img_size))

    return img_data


train_n = read_images(train_n_path, train_n_names)
train_p = read_images(train_p_path, train_p_names)
val_n = read_images(val_n_path, val_n_names)
val_p = read_images(val_p_path, val_p_names)
test_n = read_images(test_n_path, test_n_names)
test_p = read_images(test_p_path, test_p_names)


dataset_n = np.concatenate((train_n, val_n, test_n), axis=0)
dataset_p = np.concatenate((train_p, val_p, test_p), axis=0)


min_val = min(len(dataset_n), len(dataset_p))

dataset_n = dataset_n[:min_val, ...]
dataset_p = dataset_p[:min_val, ...]


index = int(min_val/10)

train_n = dataset_n[2*index:]
train_p = dataset_p[2*index:]
val_n = dataset_n[:index]
val_p = dataset_p[:index]
test_n = dataset_n[index:2*index]
test_p = dataset_p[index:2*index]


train_counts = [len(train_n), len(train_p)]
val_counts = [len(val_n), len(val_p)]
test_counts = [len(test_n), len(test_p)]

# Create subplots
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

# Function to add text on top of bars
def add_labels(ax, counts):
    # Get the y-axis limit
    y_lim = ax.get_ylim()[1]
    for i, count in enumerate(counts):
        # Add a label above the bar but below the maximum y-axis limit
        label_y = min(count + 10, y_lim - 10)  # Ensure label stays within plot
        ax.text(i, label_y, str(count), ha='center', va='bottom')

# Train dataset bar plot
axs[0].bar(categories, train_counts, color=['#1f77b4', '#ff7f0e'])
axs[0].set_title('Train Dataset')
axs[0].set_ylabel('Number of Images')
axs[0].set_ylim(0, 1500)  # Adjust y-axis limit
add_labels(axs[0], train_counts)  # Add labels

# Validation dataset bar plot
axs[1].bar(categories, val_counts, color=['#1f77b4', '#ff7f0e'])
axs[1].set_title('Validation Dataset')
axs[1].set_ylim(0, 1500)  # Adjust y-axis limit
add_labels(axs[1], val_counts)  # Add labels

# Test dataset bar plot
axs[2].bar(categories, test_counts, color=['#1f77b4', '#ff7f0e'])
axs[2].set_title('Test Dataset')
axs[2].set_ylim(0, 1500)  # Adjust y-axis limit
add_labels(axs[2], test_counts)  # Add labels

# Adjust layout and show plot
plt.tight_layout()
plt.show()


# Create subplots
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

# Training Pie Chart
axs[0].pie(train_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[0].set_title('Train Dataset')

# Validation Pie Chart
axs[1].pie(val_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[1].set_title('Validation Dataset')

# Test Pie Chart
axs[2].pie(test_counts, labels=categories, autopct='%1.1f%%', colors=['#1f77b4','#ff7f0e'])
axs[2].set_title('Test Dataset')

# Adjust layout
plt.tight_layout()

# Show plot
plt.show()





# Create a figure
fig, axs = plt.subplots(2, 8, figsize=(15, 6))

# Display Normal Images
for j in range(8):
    axs[0, j].imshow(np.uint8(train_n[j]))
    axs[0, j].axis("off")
    axs[0, j].set_xticklabels([])
    axs[0, j].set_yticklabels([])
    axs[0, j].set_aspect('equal')

# Display Pneumonia Images
for j in range(8):
    axs[1, j].imshow(np.uint8(train_p[j]))
    axs[1, j].axis("off")
    axs[1, j].set_xticklabels([])
    axs[1, j].set_yticklabels([])
    axs[1, j].set_aspect('equal')

# Add titles for each row
fig.text(0.5, 0.85, 'Normal Images', ha='center', va='center', fontsize=16)
fig.text(0.5, 0.45, 'Pneumonia Images', ha='center', va='center', fontsize=16)

# Adjust layout
plt.subplots_adjust(wspace=0.05, hspace=0.05)
plt.show()





def generate_labels(x):
    list_n = [np.array([0], dtype=np.float32) for i in range(int(len(x)/2))]
    list_p = [np.array([1], dtype=np.float32) for i in range(int(len(x)/2))]
    return np.concatenate((list_n, list_p))
    
x_train = np.concatenate((train_n, train_p), axis=0)
y_train = generate_labels(x_train)

x_val = np.concatenate((val_n, val_p), axis=0)
y_val = generate_labels(x_val)

x_test = np.concatenate((test_n, test_p), axis=0)
y_test = generate_labels(x_test)


# Shuffle the dataset
def shuffle(x, y):
    # Generate a permutation of indices
    indices = np.random.permutation(len(x))

    # Shuffle x and y with the same permutation
    return x[indices], y[indices]

x_train, y_train = shuffle(x_train, y_train)
x_val, y_val = shuffle(x_val, y_val)
x_test, y_test = shuffle(x_test, y_test)


# check the shapes of the dataset
print("x_train:", x_train.shape)
print("x_val:  ", x_val.shape)
print("x_test: ", x_test.shape)
print("y_train:", y_train.shape)
print("y_val:  ", y_val.shape)
print("y_test: ", y_test.shape)


# Pixel Value Scaling for Datasets: Normalizing and Standardizing the Data
x_train=x_train/256
x_val=x_val/256
x_test=x_test/256








def convNet():

    cnn = Sequential()
    cnn.add(Input(shape=(img_size, img_size,3)))
    cnn.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
    cnn.add(BatchNormalization())
    cnn.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
    
    cnn.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
    cnn.add(Dropout(0.1))
    cnn.add(BatchNormalization())
    cnn.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
    
    cnn.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
    cnn.add(BatchNormalization())
    cnn.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
    
    cnn.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
    cnn.add(Dropout(0.2))
    cnn.add(BatchNormalization())
    cnn.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
    
    cnn.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
    cnn.add(Dropout(0.2))
    cnn.add(BatchNormalization())
    cnn.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
    
    cnn.add(Flatten())
    cnn.add(Dense(units = 128 , activation = 'relu'))
    cnn.add(Dropout(0.2))
    cnn.add(Dense(units = 1 , activation = 'sigmoid'))
    
    return cnn

# Training The CNN
custom_model = convNet()
custom_model.compile(optimizer=Adam(learning_rate=lr), loss=loss, metrics=['binary_accuracy'])
custom_model.summary() 


start_time = time.time()
custom_hist = custom_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data= (x_val, y_val), callbacks=[PlotLossesKeras()])
custom_elapsed_time = time.time() - start_time


# Evaluate the model
custom_loss, custom_acc = custom_model.evaluate(x_test, y_test)

# Print the results
print(f"Test Loss: {custom_loss}")
print(f"Test Accuracy: {custom_acc}")





def convNet():
    base_model = ResNet152V2(weights='imagenet', include_top = False, input_shape=(img_size, img_size, 3))
    # Freeze the base model
    for layer in base_model.layers:
        layer.trainable = False

    cnn = Sequential()
    cnn.add(Input(shape=(img_size, img_size,3)))
    cnn.add(base_model)
    cnn.add(GlobalAveragePooling2D())
    cnn.add(Dense(128, activation='relu'))
    cnn.add(Dropout(0.1))
    cnn.add(Dense(1, activation='sigmoid'))
    
    return cnn

# Training The CNN
tl_model = convNet()
tl_model.compile(optimizer=Adam(learning_rate=lr), loss=loss, metrics=['binary_accuracy'])
tl_model.summary()  


start_time = time.time()
tl_hist = tl_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data= (x_val, y_val), callbacks=[PlotLossesKeras()])
tl_elapsed_time = time.time() - start_time


# Evaluate the model
tl_loss, tl_acc = tl_model.evaluate(x_test, y_test)

# Print the results
print(f"Test Loss: {tl_loss}")
print(f"Test Accuracy: {tl_acc}")





def convNet():
    base_model = ResNet152V2(weights='imagenet', include_top = False, input_shape=(img_size, img_size, 3))
    # Freeze all layers except for the
    for layer in base_model.layers[:-10]:
        layer.trainable = False

    cnn = Sequential()
    cnn.add(Input(shape=(img_size, img_size,3)))
    cnn.add(base_model)
    cnn.add(GlobalAveragePooling2D())
    cnn.add(Dense(128, activation='relu'))
    cnn.add(Dropout(0.1))
    cnn.add(Dense(1, activation='sigmoid'))
    
    return cnn

# Training The CNN
pft_model = convNet()
pft_model.compile(optimizer=Adam(learning_rate=lr), loss=loss, metrics=['binary_accuracy'])
pft_model.summary()  


start_time = time.time()
pft_hist = pft_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data= (x_val, y_val), callbacks=[PlotLossesKeras()])
pft_elapsed_time = time.time() - start_time


# Evaluate the model
pft_loss, pft_acc = pft_model.evaluate(x_test, y_test)

# Print the results
print(f"Test Loss: {pft_loss}")
print(f"Test Accuracy: {pft_acc}")





def convNet():
    base_model = ResNet152V2(weights='imagenet', include_top = False, input_shape=(img_size, img_size, 3))
    # Freeze all layers except for the
    for layer in base_model.layers:
        layer.trainable = True

    cnn = Sequential()
    cnn.add(Input(shape=(img_size, img_size,3)))
    cnn.add(base_model)
    cnn.add(GlobalAveragePooling2D())
    cnn.add(Dense(128, activation='relu'))
    cnn.add(Dropout(0.1))
    cnn.add(Dense(1, activation='sigmoid'))
    
    return cnn

# Training The CNN
fft_model = convNet()
fft_model.compile(optimizer=Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=['binary_accuracy'])
fft_model.summary()  


start_time = time.time()
fft_hist = fft_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data= (x_val, y_val), callbacks=[PlotLossesKeras()])
fft_elapsed_time = time.time() - start_time


# Evaluate the model
fft_loss, fft_acc = fft_model.evaluate(x_test, y_test)

# Print the results
print(f"Test Loss: {fft_loss}")
print(f"Test Accuracy: {fft_acc}")








histories = [custom_hist, tl_hist, pft_hist, fft_hist]
titles = ['Custom CNN', 'Transfer Learning', 'Partial Fine-Tune', 'Full Fine-Tune']

fig, axs = plt.subplots(2, 2, figsize=(14, 10))
axs = axs.flatten()

for i, history in enumerate(histories):
    axs[i].plot(history.history['binary_accuracy'], label='Training')
    axs[i].plot(history.history['val_binary_accuracy'], label='Validation')
    axs[i].set_title(titles[i] + ' Accuracy')
    axs[i].set_xlabel('Epochs')
    axs[i].set_ylabel('Accuracy')
    axs[i].legend()
    axs[i].grid(True)

plt.tight_layout()
plt.show()


fig, axs = plt.subplots(2, 2, figsize=(14, 10))
axs = axs.flatten()

for i, history in enumerate(histories):
    axs[i].plot(history.history['loss'], label='Training')
    axs[i].plot(history.history['val_loss'], label='Validation')
    axs[i].set_title(titles[i] + ' Loss')
    axs[i].set_xlabel('Epochs')
    axs[i].set_ylabel('Loss')
    axs[i].legend()
    axs[i].grid(True)

plt.tight_layout()
plt.show()





def refined_predictions(model, x):
    predictions = model.predict(x, verbose=1)
    return np.where(predictions > 0.5, 1, 0), predictions
    
custom_preds, custom_true_prds = refined_predictions(custom_model, x_test)
tl_preds, tl_true_prds = refined_predictions(tl_model, x_test)
pft_preds, pft_true_prds = refined_predictions(pft_model, x_test)
fft_preds, fft_true_prds = refined_predictions(fft_model, x_test)


def compute_scores(y_true, y_preds):
    accuracy = accuracy_score(y_true, y_preds)
    precision = precision_score(y_true, y_preds, average='weighted')
    recall = recall_score(y_true, y_preds, average='weighted')
    f1 = f1_score(y_true, y_preds, average='weighted')

    return accuracy, precision, recall, f1
    

predictins = [custom_preds, tl_preds, pft_preds, fft_preds]
        
metrics = {}

for i in range(len(titles)):
    accuracy, precision, recall, f1 = compute_scores(y_test, predictins[i])
    
    metrics[titles[i]] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }





# Convert metrics dictionary to a format suitable for plotting
metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
model_names = list(metrics.keys())
data = {metric: [metrics[model][metric] for model in model_names] for metric in metric_names}

# Plotting
fig, axs = plt.subplots(2, 2, figsize=(14, 9))
axs = axs.flatten()

for i, metric in enumerate(metric_names):
    sns.barplot(x=model_names, y=data[metric], ax=axs[i], palette='Spectral')
    axs[i].set_title(f'{metric}', fontsize=16)
    axs[i].set_ylim(0.9, 1)  # Assuming all metrics range from 0 to 1
    axs[i].set_ylabel(f'{metric} Score', fontsize=14)
    #axs[i].set_xlabel('Model', fontsize=14)
    axs[i].tick_params(axis='x', labelbottom=False)  # Remove model names from x-axis
    axs[i].set_xticks([])

# Add legend in the last subplot
handles, labels = axs[0].get_legend_handles_labels()
axs[-1].legend(handles=axs[0].patches, labels=model_names, loc='upper left', fontsize=12)

plt.tight_layout()
plt.show()





fig, axs = plt.subplots(1, 4, figsize=(11, 2.5))
axs = axs.flatten()

for i, preds in enumerate(predictins):
    cm = confusion_matrix(y_test, preds)
    sns_heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax=axs[i])
    if i != 3:
        sns_heatmap.collections[0].colorbar.ax.yaxis.set_ticks([])
    axs[i].set_title(titles[i], fontsize=14)
    axs[i].set_xlabel("Predicted Label", fontsize=12)
    axs[i].set_ylabel("True Label", fontsize=12)

plt.tight_layout()
plt.show()








# Calculate the number of trainable parameters
# This approach is not precise
def trainable_parameters(model):
    non_trainable_params = np.sum([np.prod(var.shape) for var in model.non_trainable_variables])
    return model.count_params() - non_trainable_params

custom_params = trainable_parameters(custom_model)
tl_params = trainable_parameters(tl_model)
pft_params = trainable_parameters(pft_model)
fft_params = trainable_parameters(fft_model)


print("Number of trainable parameters for Custom CNN:          ", custom_params)
print("Number of trainable parameters for Transfer Learning:   ", tl_params)
print("Number of trainable parameters for Partial Fine-Tuning: ", pft_params)
print("Number of trainable parameters for Full Fine-Tuning:    ", fft_params)


print(f"Total training time for Custom CNN:           {int(custom_elapsed_time/60)} minutes and {int(custom_elapsed_time%60)} seconds")
print(f"Total training time for Transfer Learning:    {int(tl_elapsed_time/60)} minutes and {int(tl_elapsed_time%60)} seconds")
print(f"Total training time for Partial Fine-Tuning:  {int(pft_elapsed_time/60)} minutes and {int(pft_elapsed_time%60)} seconds")
print(f"Total training time for Full Fine-Tuning:     {int(fft_elapsed_time/60)} minutes and {int(fft_elapsed_time%60)} seconds")


fig, axs = plt.subplots(1, 2, figsize=(14, 5))
axs = axs.flatten()

sns.barplot(x=model_names,
            y=[custom_elapsed_time, tl_elapsed_time, pft_elapsed_time, fft_elapsed_time],
            ax=axs[0], palette='Spectral')
axs[0].set_title("Training Time", fontsize=16)
axs[0].set_ylabel('Time (Seconds)', fontsize=14)
axs[0].tick_params(axis='x', labelbottom=False)  # Remove model names from x-axis
axs[0].set_xticks([])
axs[0].grid()

sns.barplot(x=model_names,
            y=[custom_params, tl_params, pft_params, fft_params],
                ax=axs[1], palette='Spectral')
axs[1].set_title("Memory Consumption", fontsize=16)
axs[1].set_ylabel('Number of Trainable Parameters', fontsize=14)
axs[1].tick_params(axis='x', labelbottom=False)  # Remove model names from x-axis
axs[1].set_xticks([])
axs[1].grid()
plt.yscale('log')

# Add legend in the last subplot
handles, labels = axs[0].get_legend_handles_labels()
axs[-1].legend(handles=axs[0].patches, labels=model_names, loc='upper left', fontsize=12)

plt.tight_layout()
plt.show()








custom_prds = [i.item() for i in custom_true_prds]
tl_prds = [i.item() for i in tl_true_prds]
pft_prds = [i.item() for i in pft_true_prds]
fft_prds = [i.item() for i in fft_true_prds]

prds = [custom_prds, tl_prds, pft_prds, fft_prds]


import scipy.stats as stats


# Initialize a 4x4 matrix to store p-values
p_values_matrix = np.zeros((len(prds), len(prds)))

# Compute p-values for each pair of models
for i in range(len(prds)):
    for j in range(len(prds)):
        if i != j:
            _, p_value = stats.ttest_ind(prds[i], prds[j])
            p_values_matrix[i, j] = p_value
        else:
            p_values_matrix[i, j] = True  # Set diagonal to NaN for clarity

# Create a heatmap for the p-values matrix
plt.figure(figsize=(8, 6))
sns.heatmap(p_values_matrix, annot=True, fmt='.3f', cmap='viridis_r', xticklabels=model_names, yticklabels=model_names)
plt.title('P-values Matrix for Model Comparisons')
plt.show()












